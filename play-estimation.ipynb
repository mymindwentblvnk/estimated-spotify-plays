{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimated Spotify Plays\n",
    "\n",
    "In this project I want to build a deep learning model that predicts how often I will listen to a song based on its audio features which can be retrieved via the [Spotify Web API](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/).\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "Let's have a look at the dataset I have to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 moik moik 1,5M Sep 23 11:03 dataset/hoergewohnheiten.csv\r\n",
      "-rw-r--r-- 1 moik moik  13M Sep 23 11:03 dataset/last_fm.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -alFh dataset/*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two CSV files which hold information about when (UTC timestamp) I did listen to a certain song (identifies via the combination of song title and artist name). One file is a export of [LastFM](https://mainstream.ghan.nl/export.html) the other one is from a side project I started a while ago which is called [Hoergewohnheiten](https://github.com/mymindwentblvnk/hoergewohnheiten)\n",
    "\n",
    "Let's see how files look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uts,utc_time,artist,artist_mbid,album,album_mbid,track,track_mbid\r",
      "\r\n",
      "\"1486670769\",\"09 Feb 2017, 20:06\",\"Shy Glizzy\",\"21354007-a91f-4460-934d-12d389de3a2a\",\"Homieland, Vol. 2\",\"\",\"Woah\",\"\"\r",
      "\r\n",
      "\"1486658377\",\"09 Feb 2017, 16:39\",\"Dre\",\"9ccc0b15-6506-46ba-8bca-6e35d40ebfa7\",\"Rich & Lit\",\"\",\"5 Rounds\",\"\"\r",
      "\r\n",
      "\"1486658166\",\"09 Feb 2017, 16:36\",\"Dre\",\"9ccc0b15-6506-46ba-8bca-6e35d40ebfa7\",\"Rich & Lit\",\"\",\"Fine Ass Girls\",\"\"\r",
      "\r\n",
      "\"1486507369\",\"07 Feb 2017, 22:42\",\"Cosima\",\"dcf74737-7d5b-4847-acdb-9edec6a7cea1\",\"To Build A House\",\"\",\"To Build A House\",\"\"\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 dataset/last_fm.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp,title,artist,album\r\n",
      "1530516395,\"Ella, elle l'a - Remasterisé\",France Gall,Babacar ( Remasterisé)\r\n",
      "1530516323,Get Down,Junglepussy,Jp3\r\n",
      "1530516172,State of the Union,Junglepussy,Jp3\r\n",
      "1530516088,Jammin That Screw,Trae Tha Truth,48 Hours Later\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 dataset/hoergewohnheiten.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the LastFM export has a unique identifier but that does not help with the Hoergewohnheiten data. So now I want to build the following datastructure with help of Paul Lamere's [spotipy](https://github.com/plamere/spotipy) where every row represents one track:\n",
    " \n",
    "\n",
    "| tempo | valence | energy | ... | danceability | plays |\n",
    "|-------|---------|--------|-----|--------------|-------|\n",
    "| 98.30 | 0.523   | 0.993  | ... | 0.7350       | 12    |\n",
    "| 132.4 | 0.24    | 0.451  | ... | 0.99002      | 130   |\n",
    "| 78.0  | 0.9     | 0.56   | ... | 0.12502      | 2     |\n",
    "| ...   | ...     | ...    | ... | ...          | ...   |\n",
    "\n",
    "There are the following features (see [Audio Features Object](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/)):\n",
    "\n",
    "* danceability                                                                  \n",
    "* energy                                                                        \n",
    "* key                                                                           \n",
    "* loudness                                                                      \n",
    "* mode                                                                          \n",
    "* speechiness                                                                   \n",
    "* acousticness                                                                  \n",
    "* instrumentalness                                                              \n",
    "* liveness                                                                      \n",
    "* valence                                                                       \n",
    "* tempo                                                                         \n",
    "* duration_ms\n",
    "* time_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count plays per Track\n",
    "\n",
    "First I count the amount of plays by artist name and track title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21501 plays found.\n",
      "[(['France Gall', \"Ella, elle l'a - Remasterisé\"], 2), (['Junglepussy', 'Get Down'], 1), (['Junglepussy', 'State of the Union'], 1), (['Trae Tha Truth', 'Jammin That Screw'], 5), (['Faithless', 'Insomnia'], 9), (['Faithless', 'God Is a DJ - Radio Mix'], 2), (['DJ Bobo', 'Everybody'], 6), (['Robin S', 'Show Me Love'], 1), (['Ricky Martin', \"La Copa de la Vida (La Cancion Oficial de la Copa Mundial, Francia '98) - Spanglish Radio Edit\"], 1), (['Members Of Mayday', 'Sonic Empire - Short Mix'], 1)]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "splitter = '#*#*#*#*#*#*#'\n",
    "play_data_dict = defaultdict(int)\n",
    "\n",
    "with open('dataset/hoergewohnheiten.csv', 'r') as hoergewohnheiten_in:\n",
    "    reader = csv.DictReader(hoergewohnheiten_in)\n",
    "    for row in reader:\n",
    "        temp_identifier = \"{artist}{splitter}{title}\".format(title=row['title'],\n",
    "                                                             artist=row['artist'],\n",
    "                                                             splitter=splitter)\n",
    "        play_data_dict[temp_identifier] += 1\n",
    "        \n",
    "with open('dataset/last_fm.csv', 'r') as last_fm_in:\n",
    "    reader = csv.DictReader(last_fm_in)\n",
    "    for row in reader:\n",
    "        temp_identifier = \"{artist}{splitter}{title}\".format(title=row['track'],\n",
    "                                                             artist=row['artist'],\n",
    "                                                             splitter=splitter)\n",
    "        play_data_dict[temp_identifier] += 1\n",
    "\n",
    "play_data = list(zip(\n",
    "    list([k.split(splitter) for k in play_data_dict.keys()]), \n",
    "    list(play_data_dict.values())\n",
    "))\n",
    "\n",
    "print(len(play_data), \"plays found.\")\n",
    "print(play_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Spotify information from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpotifyClient():\n",
    "    from spotipy import Spotify\n",
    "    import spotipy.util\n",
    "\n",
    "    try:\n",
    "        import spotify_settings\n",
    "        user_name = spotify_settings.USER_NAME\n",
    "        client_id = spotify_settings.CLIENT_ID\n",
    "        client_secret = spotify_settings.CLIENT_SECRET\n",
    "        redirect_uri = spotify_settings.REDIRECT_URI\n",
    "    except ImportError:\n",
    "        user_name = 'SET_THIS_YOURSELF'\n",
    "        client_id = 'SET_THIS_YOURSELF'\n",
    "        client_secret = 'SET_THIS_YOURSELF'\n",
    "        redirect_uri = 'SET_THIS_YOURSELF'\n",
    "\n",
    "    token = spotipy.util.prompt_for_user_token(\n",
    "        user_name, redirect_uri=redirect_uri,\n",
    "        client_id=client_id, client_secret=client_secret,\n",
    "        scope='user-library-read'\n",
    "    )\n",
    "    return Spotify(auth=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve for every track the Spotify id via search API\n",
    "\n",
    "At first I search for every _artist name track name_ combination to get the Spotify id for these tracks. The id is important to fetch the audio features for every song I heard in the next step. \n",
    "\n",
    "I do not want to request the Spotify API everytime, since this is a very time intensive step. So I save the results into a subfolder *search_results*. I reset the Spotify connection every 1000 requests to not run into a timeout with this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: das Verzeichnis »dataset/search_results“ kann nicht angelegt werden: Die Datei existiert bereits\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir dataset/search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path\n",
    "import hashlib\n",
    "\n",
    "\n",
    "spotify_client = SpotifyClient()\n",
    "\n",
    "print(\"Retrieving track ids\")\n",
    "\n",
    "for index, play in enumerate(play_data, 1):\n",
    "    print(index, \"/\", len(play_data), end='\\r')\n",
    "    \n",
    "    if index % 500 == 0:\n",
    "        spotify_client = SpotifyClient()  # Refresh client every n requests\n",
    "        \n",
    "    artist = play[0][1]\n",
    "    track = play[0][0]\n",
    "    plays = play[1]\n",
    "    \n",
    "    query = '{} {}'.format(artist, track)\n",
    "    query_hash = hashlib.md5(query.encode()).hexdigest()\n",
    "    \n",
    "    if not os.path.isfile('dataset/search_results/{}.json'.format(query_hash)):\n",
    "        result = spotify_client.search(q=query, type='track', limit=1)\n",
    "\n",
    "        if len(result['tracks']['items']) == 1:\n",
    "            track_id = result['tracks']['items'][0]['id']\n",
    "            query_result = {\n",
    "                'id':  track_id,\n",
    "                'track_data': result['tracks']['items'][0],\n",
    "                'artist_data': result['tracks']['items'][0]['artists'],\n",
    "                'plays': plays\n",
    "            }\n",
    "\n",
    "            with open('dataset/search_results/{}.json'.format(query_hash), 'w') as json_out:\n",
    "                json.dump(query_result, json_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch audio features per track\n",
    "\n",
    "In the next step I can fetch data from the Spotify API in batches of 50 tracks. To do so I created a generator that returns (yields) over batches of 50 of an given iterable.\n",
    "\n",
    "In the first step I had to create a list of all track ids in JSON files in *search_resuls*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "\n",
    "def batch_generator(iterable, size=50):\n",
    "    iterable = list(iterable)\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, size):\n",
    "        yield iterable[ndx:min(ndx + size, l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract track ids from the search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_ids = []\n",
    "for json_file in glob('dataset/search_results/*.json'):\n",
    "    with open(json_file, 'r') as json_in:\n",
    "        data = json.load(json_in)\n",
    "        if 'id' in data:\n",
    "            track_ids.append(data['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and get all audio features for these tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving audio features - Request 293\r"
     ]
    }
   ],
   "source": [
    "audio_features_per_track_id = dict()\n",
    "track_id_batches = batch_generator(track_ids)\n",
    "\n",
    "spotify_client = SpotifyClient()\n",
    "\n",
    "for index, batch in enumerate(track_id_batches, 1):\n",
    "    print(\"Retrieving audio features - Request\", index, end='\\r')\n",
    "    audio_features = spotify_client.audio_features(tracks=batch)\n",
    "    for feature in audio_features:\n",
    "        if feature:\n",
    "            track_id = feature['id']\n",
    "            audio_features_per_track_id[track_id] = feature\n",
    "        \n",
    "import json\n",
    "with open('dataset/audio_features.json', 'w') as json_out:\n",
    "    json.dump(audio_features_per_track_id, json_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHAT HAVE I DONE??? Yeah, I created data in two destinations:\n",
    "\n",
    "* *dataset/search_querys* which multiple JSON files that have information about a track (track id, track name, artist) and the number of times I played the track\n",
    "* *dataset/audio_features.json* which provides the Spotify audio features per track id.\n",
    "\n",
    "#### Joining the data\n",
    "\n",
    "In a last step of data preprocessing I have to join the number of plays with the audio features of a song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
